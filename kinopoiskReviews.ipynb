{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from skimage.io import imread\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import time, random\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "URL = \"https://www.livelib.ru/reviews/~%d#reviews\"\n",
    "\n",
    "def extract_reviews(parser):\n",
    "    reviews_list = []\n",
    "    \n",
    "    reviews_divs = parser.find_all(\"article\", {\"class\": \"review-card\"})\n",
    "    \n",
    "    for ind in range(len(reviews_divs)):\n",
    "        try:\n",
    "            label          = float(reviews_divs[ind].find(\"span\", {\"class\": \"lenta-card__mymark\"}).text)\n",
    "            review_content = get_name(reviews_divs[ind].find(\"div\",  {\"class\": \"lenta-card__text\"}))\n",
    "            \n",
    "            review = {\n",
    "                \"content\" : review_content, \n",
    "                \"label\" : label\n",
    "            }\n",
    "\n",
    "            reviews_list.append(review)\n",
    "        except:\n",
    "            print(\"ASD\")\n",
    "        \n",
    "    return reviews_list\n",
    "\n",
    "\n",
    "def get_name(parser):\n",
    "    text = \"\"\n",
    "    \n",
    "    for p in parser.find_all(\"p\"):\n",
    "        text += p.text\n",
    "        \n",
    "    return text\n",
    "\n",
    "\n",
    "def get_reviews_from_livelib(n_pages=1):\n",
    "    reviews = []\n",
    "\n",
    "    while n_pages:\n",
    "        reviews_list = []\n",
    "        \n",
    "        response = requests.get(URL % n_pages, headers={'User-Agent': UserAgent().chrome})\n",
    "        response.encoding = response.apparent_encoding\n",
    "        print(response.url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        reviews.extend(extract_reviews(soup))\n",
    "        time.sleep(1 + random.randint(0, 20) / 10)\n",
    "        n_pages -= 1\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "a = get_reviews_from_livelib(10)\n",
    "\n",
    "data = pd.DataFrame(a)\n",
    "\n",
    "data.to_csv(\"kino_reviews.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"kino_reviews.json\", \"w\") as file:\n",
    "    json.dump(a, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs102",
   "language": "python",
   "name": "cs102"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
