{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"\"\"\n",
    "    {\n",
    "      \"categorizedBooks\": {\n",
    "        \"68\": \"not_interested\",\n",
    "        \"138\": \"not_interested\",\n",
    "        \"185\": \"\",\n",
    "        \"263\": \"interested\",\n",
    "        \"287\": \"interested\",\n",
    "        \"341\": \"\",\n",
    "        \"401\": \"not_interested\",\n",
    "        \"414\": \"interested\",\n",
    "        \"528\": \"interested\",\n",
    "        \"622\": \"interested\",\n",
    "        \"686\": \"\",\n",
    "        \"929\": \"not_interested\"\n",
    "      }\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "a = json.loads(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kek.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    books = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_chars(text):\n",
    "    chars = [\"«\", \"»\", \"…\", \"–\", \"(\", \")\", \"[\", \"]\", \"#\", \",\", \".\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\", \":\", \"+\", \"-\", \"/\", \"\\\\\", \"-\", \"!\", \"\\\"\", \"?\"]\n",
    "    \n",
    "    for char in chars:\n",
    "        text = str(text).replace(char, \"\")\n",
    "        \n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_texts(reviews):\n",
    "    reviews_clear = []\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    stop_words = get_stop_words('ru')\n",
    "    \n",
    "    for text in reviews:\n",
    "        clear_text = ''\n",
    "\n",
    "        text = delete_chars(text)\n",
    "\n",
    "        for word in text.split():\n",
    "            normal_form = morph.parse(word)[0].normal_form\n",
    "\n",
    "            if not normal_form in stop_words:\n",
    "                clear_text += normal_form + \" \"\n",
    "\n",
    "        reviews_clear.append(clear_text)\n",
    "    \n",
    "    return reviews_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_book_by_id(book_id):\n",
    "    for book in books:\n",
    "        if book[\"id\"] == book_id:\n",
    "            return book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_by_attr(clf, book, attr):\n",
    "    \n",
    "    X_train = clean_texts([book[attr]])\n",
    "    \n",
    "    return clf.predict(X_train, prob=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_two_list(arr1, arr2):\n",
    "    for ind, el in enumerate(arr2):\n",
    "        arr1[ind] += el\n",
    "        \n",
    "    return arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_id(clf, book_id):\n",
    "    book = find_book_by_id(book_id)\n",
    "    probabilities = [0 for i in range(len(clf.labels))]\n",
    "    \n",
    "    probability_name        = get_prob_by_attr(clf, book, \"name\")\n",
    "    probability_description = get_prob_by_attr(clf, book, \"description\")\n",
    "    \n",
    "    probabilities = sum_two_list(probability_description, probability_name)\n",
    "\n",
    "    return clf.labels[probabilities.index(max(probabilities))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_by_response(clf, response):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    attrs = [\"name\", \"description\"]\n",
    "    \n",
    "    for attr in attrs:\n",
    "        for X in response[\"categorizedBooks\"]:\n",
    "            X_train.append(find_book_by_id(int(X))[attr])\n",
    "            y_train.append(response[\"categorizedBooks\"][X])\n",
    "\n",
    "        X_train = clean_texts(X_train)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NaiveBayes\n",
    "clf = NaiveBayes.NaiveBayesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = fit_by_response(clf, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not_interested'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_by_id(clf, 401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1: \"2\", 2: \"3\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '3']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_kek.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    books = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Книга Хранитель забытых вещей ( Рут Хоган ): interested\n",
      "Книга Пять поросят ( Агата Кристи ): interested\n",
      "Книга Бэтмен. Человек, который смеется ( Э. Брубейкер ): \n",
      "Книга 1793. История одного убийства ( Никлас Натт-о-Даг ): interested\n",
      "Книга Мальчик Мотл ( Шолом-Алейхем ): not_interested\n",
      "Книга Все случилось на Джеллико-роуд ( Мелина Марчетта ): interested\n",
      "Книга Волшебный корабль ( Робин Хобб ): \n",
      "Книга Ученица. Предать, чтобы обрести себя ( Вестовер Тара ): not_interested\n",
      "Книга Один в океане ( Слава Курилов ): interested\n",
      "Книга Хлеб по водам ( Ирвин Шоу ): \n",
      "Книга Ущелье дьявола ( Александр Дюма ): not_interested\n",
      "Книга Шляпа Миттерана ( Лорен Антуан ): \n"
     ]
    }
   ],
   "source": [
    "for book_id in [b['id'] for b in books]:\n",
    "    book = find_book_by_id(book_id)\n",
    "    \n",
    "    print(f\"Книга {book['name']} ( {book['author']}): {predict_by_id(clf, book_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save(\"1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs102",
   "language": "python",
   "name": "cs102"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
